%% conclusion.tex
%%


%% ==================
\chapter{Discussion}
\label{ch:Discussion}
%% ==================

In this chapter, we first summarize what we've done in this work in section~\ref{ch:Discussion:sec:Summary}. Then we conclude this thesis in section~\ref{ch:Discussion:sec:Conclusion}. At the end, we point out possible directions of future work in section~\ref{ch:Discussion:sec:Outlook}.

%% ===============================
\section{Summary}
\label{ch:Discussion:sec:Summary}
%% ===============================

In this work, we've present a new reordering approach for pre-processing before translation between English and Chinese.

English and Chinese are two very different languages. Because of the different origins and separate development of the two languages, their sentence structures differ significantly, which makes the word reordering a especially difficult problem. Unlike the most other European languages, Chinese has some distinct languages features such as the use of characters instead of letters, the use of measure words, lack of space to separate the words, more pre-modifier than post-modifier, etc.

Through the analyze of differences in word orders between the two languages, we've found out the reordering is often involved with long distance word position change, such as the shift of the whole adverbial clause in the sentence, and reordering on multiple syntactic levels, such as reordering for sentences in some special pattern, which doesn't exist or rarely used in the other language.

In order to improve the sentence structure and translation quality, we've proposed the \acf{MLT} algorithm for pre-processing the text before translation. Based on the differences in English and Chinese word orders, the algorithm detects and applies reordering rules from the syntax trees and word alignments. Reordering patterns are detected by checking if the nested tag sequences in subtrees with any number of search levels have clearly new orders in the aligned text in the target language.

At last, we've established two different \ac{SMT} systems with different data set and configurations, to conduct experiments on this reordering approach for both translation directions. The approach is tested on different configurations, with or without combining other reordering approaches. And the results of different configurations are compared and evaluated.

%% ===============================
\section{Conclusion}
\label{ch:Discussion:sec:Conclusion}
%% ===============================

We've conducted experiments in both translation directions with different \ac{SMT} configurations. From the results we can see the \ac{BLEU} scores was improved no matter when we applied our \ac{SMT} reordering method to the baseline directly or when we combined it with the other reordering methods we introduced before, i.e. short rules, long rules and tree rules based reordering methods.

When our approach was applied alone, it achieved the best \ac{BLEU} score under all these reordering methods in both translation directions. The \ac{BLEU} score of the baseline was improved by $1.61$ in the English-to-Chinese translation direction, which maked up $13.34\%$ in comparison with the baseline's \ac{BLEU} score $12.07$. And the improvement in the Chinese-to-English translation direction is $2.16$, which maked up $9.91\%$ in comparison of the baseline's \ac{BLEU} score $21.80$.
%Source-side classifier preordering for machine translation

When our approach was combined with the other reordering methods, further improvements were achieved for both translation direction. Our approach improved the \ac{BLEU} score further by $0.43$ on the English-to-Chinese translation direction, which maked up $3.57\%$ in comparison with the baseline's \ac{BLEU} score $12.07$. The \ac{BLEU} score in the Chinese-to-English direction was further improved with our approach by $0.30$, which showed a $1.37\%$ improvement in comparison with the baseline's \ac{BLEU} score $21.80$.

Our reordering approach also has some other advantages. As the translation examples we've presented, there were obvious improvements in sentence structures with our reordering approach. Besides, the approach is very efficient because it reorders the words in a pre-process, rather than during decoding phase as the hierarchical phrase-based SMT model. 

As the \ac{BLEU} score was used as a measurement for the translation quality, we conclude that the Multiple-Levels-Tree reordering approach achieved obvious improvement in the word reordering and led to better translation quality between English and Chinese.

%% ===============================
\section{Outlook}
\label{ch:Discussion:sec:Outlook}
%% ===============================

Although the translation quality was obviously improved by our reordering approach, there's still much space for further improvements. As in the results, the \ac{BLEU} scores that was achieved by the oracle reordering was still much higher than the \ac{BLEU} scores achieved by our approach. This was partially because Chinese is a very different language from English and it's also not researched so much as English. However, there are still possibilities for further research.

One direction is to design better algorithm for word reordering. Design other reordering rule types which suit translation between English and Chinese better may be possible. On the other side, it's also possible to have reordering methods other than rule-based, such as training classificators for reordering for different circumstances \citep{google}.

The other direction is to design good reordering method use less information such as syntax tree. Because syntactic parser may not be available for some unpopular languages, due to lack of research and training data, this approach enables easier adaptation to other languages.

Besides, vector representation is currently a popular topic for various tasks too \citep{oxford, Mikolov}. One possible way is to use the vector representation as the feature instead of the \ac{POS} tags, but details also need to be discussed, in order to make this approach perform well in practice. First, the vectors are continue values rather than discrete values as \ac{POS} tags, so some metric may need to be defined in order to extract reordering rules from similar patterns. The detection of similar patterns may also be time-consuming or even impossible, if the metric is complicated or not suitable for grouping similar pattern. Second if syntax tree is used for reordering, consideration may need to be taken for what is good vector representation of internal nodes or constituents as well as how to calculate it. If syntax tree is not used, information of syntactic structure may not be fully utilized, long distance reordering or syntactic structure change may not be detected. One way out is probably to use the dependency tree \citep{depend}, because each internal node is labeled with the head word of its subtree, which can be used for the vector representation. 

If a algorithm gets too complicated, it's also questionable if it will perform well in practice, since it may not be intuitive and will pose a problem for implementation sometimes. So another way to make use of vector representation for word reordering is probably design some algorithms which can utilize the vector representation in a more direct way, rather than using the rule based reordering.