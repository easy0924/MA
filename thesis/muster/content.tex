%% content.tex
%%

%% ===========================
\chapter{Foundations}
\label{ch:Foundations}
%% ===========================



%% ===========================
\section{SMT System}
\label{ch:Foundations:sec:SMTSystem}
%% ===========================

%Statistical machine translation (SMT) is a machine translation paradigm where translations are generated on the basis of statistical models whose parameters are derived from the analysis of bilingual text corpora.\cite{wikismt} One typical archit

Statistical machine translation (SMT) is the state of art machine translation paradigm. It uses a typical log-linear model which is composed of a decoder and different statistical models including phrase table, reordering model and language model. All the models are weighted with parameters which are tuned from the development data. Besides development data, training data are used for training the alignment, phrase table and other models. And test data are used for evaluation purpose. The architecture of a SMT system could be illustrated as figure $2.1$.

\begin{figure}[H]
\centering
\input{smt.tikz}
\caption{Architecture of SMT system}
\end{figure}

%% ===========================
\section{Rules Based Pre-Reodering}
\label{ch:Foundations:sec:PreReorderingSystem}
%% ===========================

Our pre-reordering method is based on reordering rules. Reordering rules are rules that tell us how we should reordering the sentences in source language before translating them. In our system, the rules are generated by using the word alignment, part-of-speech (POS) tag and syntactic tree, all of which are calculated based on the training data. After we apply the reordering rules to the source sentences, word lattices are generated. The word lattices contains all the reordering possibilities of the source sentences and are further passed to the decoder for translating. The pre-reodering system could be illustrated as figure $2.2$.

\begin{figure}[H]
\centering
\input{prereordering.tikz}
\caption{Pre-reordering system}
\end{figure}

A more detailed description of \hyperref[ch:Foundations:sec:Alignment]{word alignment}, \hyperref[ch:Foundations:sec:PosTag]{POS tag}, \hyperref[ch:Foundations:sec:SyntacticTree]{syntactic tree},
\hyperref[ch:Foundations:sec:types]{reordering rules} and 
\hyperref[ch:Foundations:sec:Lattices]{word lattices} is also clarified in the following sections.

The \hyperref[ch:ReorderingApproach]{reordering approach} we used for extracting and applying the rules is introduced in the next chapter.

%% ===========================
\section{Word Alignment}
\label{ch:Foundations:sec:Alignment}
%% ===========================

Word alignment indicate the possible alignment between words in the source sentence and words in the target sentence. For example, figure $2.3$ shows an alignment between an English sentence and a Chinese sentence.

\begin{figure}[H]
\centering
\input{alignment.tikz}
\caption{Example of word alignment}
\end{figure}
%? better example with crossing alignment?
Or it may be simply presented as index pair in the file system.
$$1-1\quad 2-1\quad 2-2\quad 3-3\quad 3-4\quad 4-5\quad 4-6\quad 5-7$$

The word alignment could be trained with the GIZA++ tool by using Expectation Maximization (EM) algorithm. From the word alignment of training data we can see the patterns how the words are reordered before and after translation. Therefore, we could extract these reordering rules and apply them on the text, which is to be translated.

%% ===========================
\section{Part-of-Speech Tag}

Part-of-speech (POS) tags are markups of words in the text, which corresponds their linguistic role in the text. Depends on the definition of the roles, the set of POS tags could be different. Besides, different languages may have different POS tag set, since they may have different linguistic features, which are relevant to translation.
\begin{figure}[H]
\centering
\input{tags.tikz}
\caption{Example of POS tags}
\end{figure}
Figure $2.4$ shows an tagged English sentence. 

Tagset? English \& Chinese how to tag?


\label{ch:Foundations:sec:PosTag}
%% ===========================

%% ===========================
\section{Syntactic Tree}
\label{ch:Foundations:sec:SyntacticTree}
%% ===========================

TODO

\begin{figure}[H]
\centering
\input{ParseTree.tikz}
\caption{Example of a parse tree}
\end{figure}

%%% ===========================
%\section{Dependency Tree}
%\label{ch:Foundations:sec:DependencyTree}
%%% ===========================

%% ===========================
\section{Reordering Rule Types}
\label{ch:Foundations:sec:types}
%% ===========================

\subsection{Short Rules}
\subsection{Long Rules}
\subsection{Tree Rules}
\label{treerules}

%% ===========================
\section{Oracle Reordering}
\label{ch:Foundations:sec:oracle}
%% ===========================



%% ===========================
\section{Lattices}
\label{ch:Foundations:sec:Lattices}
%% ===========================
A word lattice could be presented with a directed acyclic graph. The graph contains nodes and transitions, with each transition labeled with a word. One example is showed in the next page. The word lattice in the example groups different word reorderings of the same English sentence together, with each reordering corresponding a path from the beginning node to the end node. The word lattice provides different p 
pass to decoder,
probability on transitions,
probability of reordering.

\begin{landscape}
\begin{figure}
\centering
\input{Lattices.tikz}
\caption{Example of a word lattice}
\end{figure}
\end{landscape}

\section{BLEU Score}
\label{ch:Foundations:sec:bleu}
BLEU is the de facto standard in machine translation\cite{metrics}. We use BLEU score to evaluate the SMT system throughout this paper.


\section{Conclusion}

%% ===========================
\chapter{Reordering Approach}
\label{ch:ReorderingApproach}
%% ===========================

%% ===========================
\section{Reordering Problem in Chinese Translation}
\label{ch:ReorderingApproach:sec:Problem}
%% ===========================

English and Chinese belong to different language groups. As Chinese belong to the Sino-Tibet language group, while English belong to the Indo-Germanic language group. And they have also developed separately for a long time. Because of their different origins and development, they've becoming two very different languages.

Unlike the most languages in the Indo-Germanic language group, which are more close to English than Chinese, Chinese has some properties those languages don't have, such as Characters as fundamental element instead of letters, the tones, no word separation, the usage of measure words,much more simple inflections and conjugations, which raises further problem for machine translation.

Even the word order between English and Chinese is more distinct. For one, the words in Chinese have generally different origins as those in English, which leads to different vocabulary and sometimes it's very hard to found corresponding words in the other language. For example, Chinese has a lot of different prepositions and adverbs, which have very distinct usage as those in English. Also the continuous writing of Chinese without space makes this problem more severe, since word boundaries are not always so clear in Chinese. Text needs to be segmented before translation, and a word segmentation program decide how to separate the words and the result is not always ideal.

For the other, 

And sometimes, a long English sentence with clauses is more suitable to be translated into two of more Chinese sentences. Through analyzing the data we have, we've found several major word order differences between English and Chinese, which leads to low translation quality and should be changed. 

%? examples of different kinds for word order differences
\textbf{Position of adverbs and adverbial clauses} v
%% ===========================
\section{Motivation of the SMT Reordering Algorithm}
\label{ch:ReorderingApproach:sec:Motivation}
%% ===========================


%? long distance position change, unstructural position change.


efficient than hier

use tree and alignment only

%% ===========================
\section{The SMT Reordering Algorithm}
\label{ch:ReorderingApproach:sec:Algorithm}
%% ===========================

%? Our method

The algorithm solely uses information of the syntactic tree and alignment of the source side. In the first part of this section, we first explain what are reordering rules from multiple layers of the syntactic tree. Afterwards we'll explain how to extract and apply the rules systematically.

\subsection{Reordering Rules from Multiple Layers}

Inspired the method of tree rules based of reordering and hierarchical SMT model, we created this reordering method. In this method we use information from the syntactic tree and further explore its syntactic structure. 



\subsection{Rule Extraction}



\subsection{Rule Application}

\section{Conclusion}

advantages